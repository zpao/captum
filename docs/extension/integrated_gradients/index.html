<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Integrated Gradients · Captum</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="## Integrated Gradients"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Integrated Gradients · Captum"/><meta property="og:type" content="website"/><meta property="og:url" content="https://captum.ai/"/><meta property="og:description" content="## Integrated Gradients"/><meta property="og:image" content="https://captum.ai/img/captum-icon.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://captum.ai/img/captum.png"/><link rel="shortcut icon" href="/img/captum.ico"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-139570076-2', 'auto');
              ga('send', 'pageview');
            </script><link rel="stylesheet" href="/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/captum_logo.svg" alt="Captum"/></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class="siteNavGroupActive"><a href="/docs/introduction" target="_self">Docs</a></li><li class=""><a href="/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/api/" target="_self">API Reference</a></li><li class=""><a href="https://github.com/pytorch/captum" target="_self">GitHub</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Usage</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">About</h3><ul class=""><li class="navListItem"><a class="navItem" href="/docs/introduction">Introduction</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">General</h3><ul class=""><li class="navListItem"><a class="navItem" href="/docs/getting_started">Getting Started</a></li><li class="navListItem"><a class="navItem" href="/docs/captum_insights">Captum Insights</a></li><li class="navListItem"><a class="navItem" href="/docs/algorithms">Algorithms</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Usage</h3><ul class=""><li class="navListItem navListItemActive"><a class="navItem" href="/docs/extension/integrated_gradients">Integrated Gradients</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="post"><header class="postHeader"><a class="edit-page-link button" href="https://github.com/pytorch/captum/edit/master/docs/extension/integrated_gradients.md" target="_blank" rel="noreferrer noopener">Edit</a><h1 class="postHeaderTitle">Integrated Gradients</h1></header><article><div><span><h2><a class="anchor" aria-hidden="true" id="integrated-gradients"></a><a href="#integrated-gradients" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Integrated Gradients</h2>
<p>This section of the documentation shows how to apply integrated gradients on
models with different types of parameters and inputs using Captum.</p>
<h3><a class="anchor" aria-hidden="true" id="description"></a><a href="#description" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Description</h3>
<p><a href="https://arxiv.org/pdf/1703.01365.pdf">Integrated gradients</a> is a simple, yet powerful axiomatic attribution method that requires almost no modification of the original network. It can be used for augmenting accuracy metrics, model debugging and feature or rule extraction.</p>
<p>Captum provides a generic implementation of integrated gradients that can be used with any PyTorch model.
In this section of the tutorial we will describe how to apply integrated gradients for output predictions.
Here is an example code snippet that reproduces the results from the <a href="https://arxiv.org/pdf/1703.01365.pdf">original paper</a> (page 10).</p>
<p>First, let's create a sample ToyModel, which computes a simple function on two inputs.</p>
<pre><code class="hljs"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ToyModel</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-string">r"""
    Example toy model from the original paper (page 10)

    https://arxiv.org/pdf/1703.01365.pdf


    f(x1, x2) = RELU(ReLU(x1) - 1 - ReLU(x2))
    """</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
        super().__init__()

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, input1, input2)</span>:</span>
        relu_out1 = F.relu(input1)
        relu_out2 = F.relu(input2)
        <span class="hljs-keyword">return</span> F.relu(relu_out1 - <span class="hljs-number">1</span> - relu_out2)
</code></pre>
<p>Second, let's apply integrated gradients on the toy model's output layer using sample data.
The code snippet below computes the attribution of output with respect to the inputs.
<code>attribute</code> method of <code>IntegratedGradients</code> class returns input attributions which
have the same size and dimensionality as the inputs and an approximation error which
is computed based on the completeness property of the integrated gradients.
Completeness property is one of the axioms that integrated gradients satisfies.
It states that the sum of the attributions must be equal to the difference between
the output of the DNN function F at the inputs and corresponding baselines.
The baselines also have the same shape and dimensionality as the inputs and if not
provided zero is used as default value.</p>
<pre><code class="hljs"><span class="hljs-keyword">from</span> captum.attr import IntegratedGradients
model = ToyModel()

<span class="hljs-comment"># defining model input tensors</span>
input1 = torch.tensor([3.0], <span class="hljs-attribute">requires_grad</span>=<span class="hljs-literal">True</span>)
input2 = torch.tensor([1.0], <span class="hljs-attribute">requires_grad</span>=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># defining baselines for each input tensor</span>
baseline1 = torch.tensor([0.0])
baseline2 = torch.tensor([0.0])

<span class="hljs-comment"># defining and applying integrated gradients on ToyModel and the</span>
ig = IntegratedGradients(model)
attributions, approximation_error = ig.attribute((input1, input2),
                                                 baselines=(baseline1, baseline2),
                                                 <span class="hljs-attribute">method</span>=<span class="hljs-string">'gausslegendre'</span>)
output

<span class="hljs-built_in">..</span><span class="hljs-built_in">..</span><span class="hljs-built_in">..</span><span class="hljs-built_in">..</span><span class="hljs-built_in">..</span><span class="hljs-built_in">..</span><span class="hljs-built_in">..</span><span class="hljs-built_in">..</span><span class="hljs-built_in">..</span>.

attributions: (tensor([1.5000], <span class="hljs-attribute">grad_fn</span>=&lt;MulBackward0&gt;),
               tensor([-0.5000], <span class="hljs-attribute">grad_fn</span>=&lt;MulBackward0&gt;))

approximation_error (aka delta): 1.1801719665527344e-05
</code></pre>
<p>Now let's look at a simple classification model. The network architecture of this
classification model is based on the network described in:
<a href="https://adventuresinmachinelearning.com/pytorch-tutorial-deep-learning/">https://adventuresinmachinelearning.com/pytorch-tutorial-deep-learning/</a></p>
<pre><code class="hljs">import torch
import torch.nn as nn
import torch.nn.functional as F

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ToySoftmaxModel</span>(<span class="hljs-title">nn</span>.<span class="hljs-title">Module</span>):</span>
    r<span class="hljs-string">""</span><span class="hljs-string">"
    Model architecture from:

    https://adventuresinmachinelearning.com/pytorch-tutorial-deep-learning/
    "</span><span class="hljs-string">""</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, num_in, num_hidden, num_out)</span></span>:
        <span class="hljs-keyword">super</span>().__init_<span class="hljs-number">_</span>()
        <span class="hljs-keyword">self</span>.num_in = num_in
        <span class="hljs-keyword">self</span>.num_hidden = num_hidden
        <span class="hljs-keyword">self</span>.num_out = num_out
        <span class="hljs-keyword">self</span>.lin1 = nn.Linear(num_in, num_hidden)
        <span class="hljs-keyword">self</span>.lin2 = nn.Linear(num_hidden, num_hidden)
        <span class="hljs-keyword">self</span>.lin3 = nn.Linear(num_hidden, num_out)
        <span class="hljs-keyword">self</span>.softmax = nn.Softmax(dim=<span class="hljs-number">1</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, input)</span></span>:
        lin1 = F.relu(<span class="hljs-keyword">self</span>.lin1(input))
        lin2 = F.relu(<span class="hljs-keyword">self</span>.lin2(lin1))
        lin3 = <span class="hljs-keyword">self</span>.lin3(lin2)
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">self</span>.softmax(lin3)
</code></pre>
<p>Now, let's apply integrated gradients on the toy classification model defined
above using inputs that contain a range of numbers. We also choose an arbitrary
target class (target_class_index: 5) which we use to attribute our predictions to.
Similar to previous example the output of attribution is a tensor with the same
dimensionality as the inputs and an approximation error computed based on the
completeness property of integrated gradients.</p>
<pre><code class="hljs"><span class="hljs-keyword">from</span> captum.attr import IntegratedGradients
num_in = 40
input = torch.arange(0.0, num_in * 1.0, <span class="hljs-attribute">requires_grad</span>=<span class="hljs-literal">True</span>).unsqueeze(0)

<span class="hljs-comment"># 10-class classification model</span>
model = SoftmaxModel(num_in, 20, 10)

<span class="hljs-comment"># attribution score will be computed with respect to target class</span>
target_class_index = 5

<span class="hljs-comment"># applying integrated gradients on the SoftmaxModel and input data point</span>
ig = IntegratedGradients(model)
attributions, approximation_error = ig.attribute(input, <span class="hljs-attribute">target</span>=target)

<span class="hljs-comment"># The input and returned corresponding attribution have the</span>
<span class="hljs-comment"># same shape and dimensionality.</span>

output

<span class="hljs-built_in">..</span><span class="hljs-built_in">..</span><span class="hljs-built_in">..</span><span class="hljs-built_in">..</span><span class="hljs-built_in">..</span><span class="hljs-built_in">..</span><span class="hljs-built_in">..</span><span class="hljs-built_in">..</span><span class="hljs-built_in">..</span>.

attributions: (tensor([[ 0.0000,  0.0014,  0.0012,  0.0019,  0.0034,  0.0020, -0.0041,  
          0.0085, -0.0016,  0.0111, -0.0114, -0.0053, -0.0054, -0.0095,  0.0097, -0.0170,
          0.0067,  0.0036, -0.0296,  0.0244,  0.0091, -0.0287,  0.0270,  0.0073,
         -0.0287,  0.0008, -0.0150, -0.0188, -0.0328, -0.0080, -0.0337,  0.0422,
          0.0450,  0.0423, -0.0238,  0.0216, -0.0601,  0.0114,  0.0418, -0.0522]],
       <span class="hljs-attribute">grad_fn</span>=&lt;MulBackward0&gt;),)

approximation_error (aka delta): 0.00013834238052368164

assert attributions.shape == input.shape
</code></pre>
<p>Now, let's look at a model that besides input tensors takes input arguments of
other types. In practice this can be used to pass the sequence length or the
word/token indices in a sequence of a text, for instance. The example below
demonstrates how to use <code>additional_forward_args</code>. In this particular example
<code>additional_forward_args</code> represents single integer value.
Those arguments are passed as <code>additional_forward_args</code> to <code>attribute</code> method and
they will be passed to model's forward function followed by inputs in the oder
provided in <code>additional_forward_args</code>. In the example below, we also demonstrate
how to apply integrated gradients to a batch of samples. The first dimension of
the input corresponds to the batch size.
In this case, batch size is equal to two.</p>
<pre><code class="hljs"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ToyModel_With_Additional_Forward_Args</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-string">r"""
        Slightly modified example model from the paper
        https://arxiv.org/pdf/1703.01365.pdf
        f(x1, x2) = RELU(ReLU(x1 - 1) - ReLU(x2))
    """</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
        super().__init__()
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, input1, input2, index)</span>:</span>
        relu_out1 = F.relu(input1 - <span class="hljs-number">1</span>)
        relu_out2 = F.relu(input2)
        <span class="hljs-keyword">return</span> F.relu(relu_out1 - relu_out2)[:, index]
</code></pre>
<p>Now, let's apply integrated gradients on the model defined above and specify
<code>additional_forward_args</code> parameter in addition to others.</p>
<pre><code class="hljs"><span class="hljs-keyword">from</span> captum.attr <span class="hljs-keyword">import</span> IntegratedGradients

input1 = torch.tensor([[<span class="hljs-number">1.0</span>, <span class="hljs-number">3.0</span>], [<span class="hljs-number">3.0</span>, <span class="hljs-number">5.0</span>]], requires_grad=True)
input2 = torch.tensor([[<span class="hljs-number">1.0</span>, <span class="hljs-number">4.0</span>], [<span class="hljs-number">0.0</span>, <span class="hljs-number">2.0</span>]], requires_grad=True)
# Initializing our toy model
model = ToyModel_With_Additional_Forward_Args()
# Applying <span class="hljs-built_in">int</span>egrated gradients on the input
ig = IntegratedGradients(model)
(input1_attr, input2_attr), delta = ig.attribute((input1, input2), n_steps=<span class="hljs-number">100</span>,
                                    additional_forward_args=<span class="hljs-number">1</span>)
output
.........
input1_attr: tensor([[<span class="hljs-number">0.0000</span>, <span class="hljs-number">0.0000</span>],
                     [<span class="hljs-number">0.0000</span>, <span class="hljs-number">3.3428</span>]], grad_fn=&lt;MulBackward0&gt;)
input2_attr:  tensor([[ <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.0000</span>],
                      [<span class="hljs-number">0.0000</span>, <span class="hljs-number">-1.3371</span>]], grad_fn=&lt;MulBackward0&gt;)
approximation_error (aka delta): <span class="hljs-number">0.005693793296813965</span>
</code></pre>
<p>In addition to the parameters described above integrated gradients also allows to specify
integral approximation type with the argument <code>method</code> which accepts the following values:
<code>riemann_right</code>, <code>riemann_left</code>, <code>riemann_middle</code>, <code>riemann_trapezoid</code> and <code>gausslegendre</code>.
The latter approximates the fastest and is used as a default approximation  method.
Besides approximation type the user can also specify the number of approximation
steps using <code>n_steps</code> input argument. The latter can be used to find a tradeoff
between approximation speed and the accuracy.</p>
<h4><a class="anchor" aria-hidden="true" id="more-details-on-how-to-apply-integrated-gradients-on-larger-dnn-networks-can-be-found-here"></a><a href="#more-details-on-how-to-apply-integrated-gradients-on-larger-dnn-networks-can-be-found-here" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>More details on how to apply integrated gradients on larger DNN networks can be found here</h4>
<ul>
<li><a href="/tutorials/CIFAR_TorchVision_Interpret">A simple classification model and CIFAR Dataset</a></li>
<li><a href="/tutorials/Resnet_TorchVision_Interpret">Torchvision's ResNet18 Model using handpicked images</a></li>
<li><a href="/tutorials/IMDB_TorchText_Interpret">Sentiment classification model using TorchText and IMDB Dataset</a></li>
<li><a href="/tutorials/Multimodal_VQA_Interpret">Visual Question Answering Model</a></li>
<li><a href="/tutorials/Titanic_Basic_Interpret">A simple DNN with 2 hidden layers and Titanic Dataset</a></li>
</ul>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="/docs/algorithms"><span class="arrow-prev">← </span><span>Algorithms</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#integrated-gradients">Integrated Gradients</a><ul class="toc-headings"><li><a href="#description">Description</a></li></ul></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><div class="footerSection"><h5>Docs</h5><a href="/docs/introduction">Introduction</a><a href="/docs/getting_started">Getting Started</a><a href="/tutorials/">Tutorials</a><a href="/api/">API Reference</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/zpao/captum" data-count-href="https://github.com/zpao/captum/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star Captum on GitHub">captum</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright"> Copyright © 2019 Facebook Inc.</section><script>
            (function() {
              var BAD_BASE = '/captum/';
              if (window.location.origin !== 'https://captum.ai') {
                var pathname = window.location.pathname;
                var newPathname = pathname.slice(pathname.indexOf(BAD_BASE) === 0 ? BAD_BASE.length : 1);
                var newLocation = 'https://captum.ai/' + newPathname;
                console.log('redirecting to ' + newLocation);
                window.location.href = newLocation;
              }
            })();
          </script></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '207c27d819f967749142d8611de7cb19',
                indexName: 'captum',
                inputSelector: '#search_input_react'
              });
            </script></body></html>